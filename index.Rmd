---
title: "Analisis Tasa de Intervencion"
author: "Gabriel Orozco/Diana Aguirre/Edgard Camacho"
date: "2024-10-21"
output: document.html
---

# **Enunciado**

En este momento deberemos retomar la Unidad 1 en la cual se cre칩 un minilibro que contiene el entregable de dicha unidad. Este documento tiene como repositorio GitHub (elaborado desde Markdown). Ahora, en esta Unidad 2, se debe continuar con los datos presentados en dicho entregable y se debe evidenciar, en una de las variables en el tiempo, la aproximaci칩n en promedio m칩vil, en rezagos y en estacionalidad. Todo lo anterior, a trav칠s de funciones y gr치ficas que permitan detectar patrones y ciclos de la variable.

## An치lisis exploratorio

```{r echo=FALSE, message=FALSE}
#install.packages("readxl")
#install.packages("forecast")
#install.packages("timsac")
#install.packages("changepoint")
#install.packages("kableExtra")
#install.packages("bookdown")
#install.packages("xfun")
#install.packages("bookdown")
#install.packages("fabletools")
#install.packages("Rcpp")
#install.packages("prophet")
#install.packages("robust")
#install.packages("tsoutliers")
#install.packages("lubridate")
#install.packages("RSNNS")
#install.packages("nnfor")




library(TSA)
library(kableExtra)
library(tidyr)
library(zoo)
library(readxl)
library(forecast) # Recomendada profesora
library(ggplot2)
library(tseries) # Recomendada profesora
library(timsac)
library(changepoint)
library(ggplot2)
library(dplyr)
library(lubridate)
library(stats)
library(bookdown)
library(fabletools)
library(Rcpp)
library(prophet)
library(robust)
library(tsoutliers)
library(nnfor)
library(RSNNS)
library(prophet)
library(lubridate)
library(forecast)# NUEVA POR BOX Jenkins
library(tsoutliers)# NUEVA POR BOX Jenkins
library(timsac) # NUEVA POR BOX Jenkins
library(TSA)
library(kableExtra)
library(tidyr)
library(zoo)
library(readxl)
library(forecast) # Recomendada profesora
library(ggplot2)
library(tseries) # Recomendada profesora
library(timsac)
library(changepoint)
library(ggplot2)
library(dplyr)
library(lubridate)
library(stats)


```


```{r echo=FALSE}
data <- read_excel("1.2.TIP_Serie historica diaria.xlsx")
```

```{r echo=FALSE, warning=FALSE}
str(data)
```

Los datos representan una serie de tiempo de 310 filas y 2 columnas, correspondientes a la fecha y a la tasa. Se observa que la fecha realmente corresponde a un dato mensual por tanto conviene ajustar el formato.


```{r echo=FALSE, warning=FALSE}
# Primer y 칰ltimo registro del dataset
resultado <- rbind(head(data, 1), tail(data, 1))
print(resultado)

```
Al consultar el primer y 칰ltimo registro del dataset, se identifica que la observaci칩n m치s reciente corresponde al mes de octubre de 2024 con una tasa de 10.25%, mientras que el registro m치s antiguo es de enero de 1999, con una tasa de 26%. Estos datos indican que el dataset abarca un periodo de aproximadamente 25 a침os (310 meses), desde finales del siglo XX hasta la fecha actual, reflejando un amplio intervalo temporal que podr칤a incluir distintas tendencias o cambios econ칩micos en la variable Tasa.

```{r echo=FALSE, warning=FALSE}
summary(data)
```

* La serie cubre un rango de 25 a침os, con la mediana alrededor de 2011, lo que sugiere que los datos est치n relativamente bien distribuidos a lo largo del tiempo.
*  La tasa tiene una amplia variabilidad, con un valor m칤nimo de 1.75 y un m치ximo de 26. La mayor parte de los valores se concentran entre 4.25 y 9.25 (entre el primer y tercer cuartil). 

No se identifican datos ausentes:

```{r echo=FALSE, warning=FALSE}
n_nas_por_columna <- colSums(is.na(data))
print(n_nas_por_columna)
```




```{r echo=FALSE, warning=FALSE}
#Se realiza una copia del dataset por seguridad.
data2 <- data

```

Con el c칩digo siguiente, se agregan dos columnas adicionales, llamadas **A침o** y **Mes**, lo anterior para poder tener una mejor visual de los datos, teniendo en cuenta el gran n칰mero de registros que tiene el dataset.


```{r echo=FALSE, warning=FALSE}


data2 <- data2 %>%
  mutate(Fecha = as.Date(Fecha), Anio = year(Fecha), Mes = month(Fecha, label = TRUE, abbr = TRUE)) %>%
  select(Anio, Mes, everything())

head(data2)



```

## Gr치ficos de visualizaci칩n


```{r echo=FALSE, warning=FALSE}

ggplot(data2, aes(x = Fecha, y = Tasa)) +
  geom_point(color = "blue", size = 2) + 
  geom_smooth(method = "loess", color = "red", se = FALSE) +  
  labs(title = "Tasa a lo largo del tiempo",
       x = "Tiempo",
       y = "Tasa") +
  scale_x_date(date_labels = "%Y-%m", date_breaks = "1 month") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.grid.major = element_line(color = "lightgrey"),
    panel.grid.minor = element_blank()
  )


```



* **Puntos Azules:** Los puntos azules indican los valores de "Tasa" en momentos espec칤ficos. Hay una dispersi칩n considerable, sugiriendo que la tasa ha experimentado fluctuaciones a lo largo del tiempo.

* **L칤nea Roja:** Esta l칤nea es el resultado de un ajuste de suavizaci칩n. La l칤nea roja ilustra la tendencia general de la "Tasa" a lo largo del tiempo. A partir de la l칤nea, se puede observar que, aunque hay variaciones, existe una tendencia que se puede analizar para hacer predicciones o entender mejor el comportamiento de la variable.

* **Variaciones:** La gr치fica muestra que la Tasa ha tenido picos y valles, lo que podr칤a indicar variaciones estacionales o influencias externas que afectan la variable a lo largo del tiempo. A partir de la l칤nea de suavizaci칩n, parece que la Tasa ha ido disminuyendo o estabiliz치ndose en ciertos per칤odos, teniendo una ca칤da significativa desde 1999 hasta 2003,  y un aumento importante de 2021 a 2024.



```{r echo=FALSE, warning=FALSE}

# 3. Gr치fico de Puntos y L칤nea de Tendencia

ggplot(data2, aes(x = Anio, y = Tasa)) +
  geom_point(color = "blue", size = 2) +  # Puntos en azul
  geom_line(color = "blue", size = 1) +  # L칤nea azul
  geom_smooth(method = "loess", color = "red", se = FALSE) +  # Tendencia en rojo
  labs(title = "Tasa a lo largo del tiempo",
       x = "Anio",
       y = "Tasa") +
  scale_x_continuous(breaks = seq(min(data2$Anio), max(data2$Anio), by = 2)) +  # Eje X de 2 en 2
  scale_y_continuous(breaks = seq(min(data2$Tasa, na.rm = TRUE), max(data2$Tasa, na.rm = TRUE), by = 2)) +  # Eje Y de 2 en 2
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.grid.major = element_line(color = "lightgrey")
  )

```


  
  
Esta gr치fica permite ver con m치s detalle los cambios de tendencia:

* Desde 1999, se confirma la disminuci칩n significativa en la tasa, que empieza muy alta (cerca de 25) y cae r치pidamente hasta estabilizarse alrededor de los a침os 2007-2008 en un valor muy inferior (por debajo de 10).

* Entre 2005 y 2020, se observan picos y ca칤das a intervalos relativamente regulares, pero sin grandes cambios en los niveles generales hasta el repunte final.

* Eentre 2010 y 2020, la tasa se mantiene m치s estable, con algunas oscilaciones en torno a los 5-10 puntos.

* A partir de 2021, hay una tendencia de aumento, que se hace m치s pronunciada hacia los a침os m치s recientes.  Esto podr칤a ser consecuencia de alg칰n cambio en las pol칤ticas o factores externos como la pandemia de COVID-19.

* La l칤nea de tendencia suavizada indica una ca칤da r치pida, seguida de un periodo de estabilizaci칩n, y finalmente una tendencia de aumento en los a침os recientes, semejando una forma de "U" suavizada.



```{r echo=FALSE, warning=FALSE}

# Crear la tabla de tasas por A침o y Mes
tabla_tasas <- data2 %>%
  group_by(Anio, Mes) %>%
  summarise(TasaPromedio = round(mean(Tasa, na.rm = TRUE), 1)) %>%  
  pivot_wider(names_from = Mes, values_from = TasaPromedio)  

# Mostrar la tabla en cuadr칤cula
kable(tabla_tasas, format = "html") %>%
  kable_styling(full_width = F, position = "left")


```

 A partir de la tabla se pueden confirmar las tendencias mencionadas anteriormente, con un comportamiento descendente en los 12 primeros a침os (1999 a 2010), una estabilizaci칩n en los 5 a침os siguientes (2011-2015) y un incremento significativo en a침os recientes (2021 en adelante).



```{r echo=FALSE}

plot(data2$Anio, data2$Tasa, main = "Grafico del dataset", xlab = "Tiempo", ylab = "Tasa")

```
  
El **gr치fico de dispersi칩n temporal**, presenta una tendencia decreciente al inicio (antes de 2005), seguida por un per칤odo de estabilizaci칩n y una ligera recuperaci칩n hacia 2020. Despu칠s de 2020, la tasa muestra un aumento significativo. La ca칤da inicial y el posterior aumento alrededor de 2020 son destacables. 


## An치lisis de serie de tiempo

## Promedio o media m칩vil


Permite analizar el mercado a trav칠s de las tendencias. La media m칩vil es una t칠cnica estad칤stica que se utiliza para analizar datos a lo largo del tiempo. Permite calcular la media de un conjunto de valores en un intervalo espec칤fico y luego desplazar ese intervalo a lo largo de la serie de datos para obtener una nueva serie de medias; lo que permite suavizar fluctuaciones en los datos as칤 como resaltar tendencias.

Se conoce como media m칩vil ya que el valor se calcula constantemente a medida que pasa el tiempo; de esta forma, la media cambia cada vez que los valores presentan alguna modificaci칩n.


```{r echo=FALSE}
# Calcular el promedio m칩vil
data2$PromedioMovil <- rollmean(data2$Tasa, k = 3, fill = NA, align = "right")

# Visualizar la tasa original y el promedio m칩vil
ggplot(data2) +
  geom_line(aes(x = Fecha, y = Tasa), color = "blue", size = 1, group = 1) +  # Tasa original
  geom_line(aes(x = Fecha, y = PromedioMovil), color = "red", size = 1, group = 1) +  # Promedio m칩vil
  labs(title = "Tasa y Promedio Movil a lo largo del tiempo",
       x = "Fecha",
       y = "Tasa") +
  scale_x_date(date_labels = "%Y", date_breaks = "2 years") +  # Eje X de 2 en 2 a침os
  scale_y_continuous(breaks = seq(0, max(data2$Tasa, na.rm = TRUE), by = 2)) +  # Eje Y de 2 en 2
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold"),
    panel.grid.major = element_line(color = "lightgrey"),
    panel.grid.minor = element_blank()
  )


```


## Rezago (operador backshift) y estacionalidad


El rezago es una herramienta estad칤stica para el an치lisis de series temporales, que permite observar el valor de una variable en un momento anterior, facilitando la identificaci칩n de patrones y tendencias a lo largo del tiempo.

En cuanto a la estacionalidad, hace referencia a las variaciones peri칩dicas y predecibles en los datos que ocurren en intervalos regulares.

Con la incorporaci칩n de ambas herramientas es posible modelar y prever comportamientos futuros de las series temporales.



```{r echo=FALSE, warning=FALSE}

# Aplicar rezago de 1 per칤odo 
data2$Tasa_lag1 <- dplyr::lag(data2$Tasa, n = 1)
head(data2)

```  
```{r echo=FALSE, warning=FALSE}

if (!is.ts(data2)) {
  data2 <- ts(data2)
}

# Verificar si hay valores NA o infinitos
if (any(is.na(data2)) || any(!is.finite(data2))) {
  data2 <- na.omit(data2)  # Eliminar valores NA
}

# Generar el gr치fico de rezago
lag.plot(data2, lags = 3, do.lines = FALSE, main = "Grafico de Rezago")

```

La gr치fica visualiza la correlaci칩n entre una variable y sus valores rezagados (delayed values). Este gr치fico es 칰til para detectar patrones en series temporales y evaluar la autocorrelaci칩n en los datos.


* **A침o vs Rezagos (lag 1, 2, 3)**

Las gr치ficas entre A침o y sus diferentes rezagos muestran una relaci칩n lineal perfecta, lo que era de esperarse, ya que el valor de un a침o en un rezago anterior est치 directamente relacionado con los a침os consecutivos. Esto sugiere que el "A침o" no aporta una variabilidad significativa en t칠rminos de cambios bruscos, es decir, la serie avanza sin saltos.


* **Mes vs Rezagos (lag 1, 2, 3)**

Las gr치ficas entre "Mes" y sus rezagos muestran una estructura c칤clica, con puntos que siguen un patr칩n predecible. Esto tiene sentido, ya que los meses siguen un ciclo repetitivo de 12 unidades (de enero a diciembre).

Los meses correlacionan bien con sus rezagos inmediatos, pero a medida que aumenta el n칰mero de rezagos (lag 2, lag 3), el ciclo es m치s visible, lo que indica que la periodicidad estacional en los datos est치 bien representada.


* **Fecha vs Rezagos (lag 1, 2, 3)**

Similar al a침o, la relaci칩n entre "Fecha" y sus rezagos tambi칠n muestra una estructura lineal. Esto era previsible, ya que las fechas est치n organizadas de manera continua. No se observan cambios abruptos o interrupciones que puedan se침alar eventos singulares en la serie temporal.

* **Tasa vs Rezagos (lag 1, 2, 3)**

En las gr치ficas entre "Tasa" y sus rezagos, especialmente en el rezago 1 (lag 1), se aprecia una clara correlaci칩n positiva, lo que significa que la tasa en un mes est치 fuertemente relacionada con la tasa del mes anterior. Esta relaci칩n indica una persistencia en la tasa, es decir, no hay cambios abruptos entre periodos consecutivos.

A medida que el rezago aumenta (lag 2 y lag 3), la relaci칩n sigue siendo positiva pero disminuye levemente, lo cual es normal: los valores m치s distantes en el tiempo tienen menos influencia directa entre s칤, aunque todav칤a se observa cierta correlaci칩n.

Esto sugiere que la serie de tasas no presenta grandes fluctuaciones a corto plazo y que los valores siguen un comportamiento m치s estable, lo que puede indicar una tendencia suave sin variaciones abruptas.


* **Promedio Movil vs Rezagos (lag 1, 2, 3)**

Similar a la "Tasa", las gr치ficas entre el "Promedio M칩vil" y sus rezagos muestran una alta correlaci칩n, especialmente para lag 1. Esto sugiere que los promedios m칩viles no cambian dr치sticamente de un mes a otro, y los valores del promedio m칩vil est치n fuertemente ligados a los meses anteriores.
A medida que aumenta el rezago (lag 2, lag 3), la correlaci칩n disminuye ligeramente, lo que indica que los valores anteriores siguen teniendo una influencia pero con una menor magnitud.


* **Tasa Lag1 vs Rezagos**

Las gr치ficas entre "Tasa_lag1" y sus rezagos tambi칠n muestran una alta correlaci칩n. Esto es de esperar, ya que los valores rezagados de una variable tienden a mostrar correlaci칩n fuerte con rezagos cercanos.

Los gr치ficos de rezago muestran una clara autocorrelaci칩n tanto en las variables de "Tas"a" como en el "Promedio M칩vil", lo que sugiere que los valores actuales est치n muy influenciados por sus valores anteriores.

No se observan grandes fluctuaciones o cambios abruptos en la serie temporal, lo que implica que los datos de tasa y promedio m칩vil siguen una evoluci칩n suave a lo largo del tiempo.

La estructura c칤clica en los meses sugiere que existe un patr칩n estacional predecible, lo cual es clave para definir modelos de predicci칩n de series temporales con componentes estacionales, como modelos ARIMA/SARIMA o de descomposici칩n estacional.



## Descomposici칩n

Con la funci칩n stl(), se descompone la serie en tendencia, estacionalidad y componente residual.

```{r echo=FALSE}

data2 <- as.data.frame(data2)

# Convertir los datos a un objeto ts, usando frecuencia mensual
ts_data <- ts(data2[["Tasa"]], start = c(1999, 5), frequency = 12)

# Descomposici칩n de la serie de tiempo
descomposicion <- stl(ts_data, s.window = "periodic")

# Graficar la descomposici칩n
plot(descomposicion, main = "Descomposicion de la Serie de Tiempo")

```

Con el gr치fico correcto de descomposici칩n, evidenciamos:

* **Data (Serie Original):**

Se observa que las tasas de inter칠s han pasado por varios ciclos a lo largo del tiempo, con un periodo inicial en el que las tasas eran m치s bajas (cerca de los a침os 2000). A partir de 2020, las tasas muestran un claro incremento, lo que puede reflejar una pol칤tica monetaria m치s restrictiva o la respuesta del Banco de la Rep칰blica a factores como la inflaci칩n o la estabilidad macroecon칩mica.


* **Seasonal (Componente Estacional):**

El componente estacional revela un ciclo repetitivo bastante regular a lo largo de los a침os, con un patr칩n de estacionalidad que parece repetirse anualmente. La estacionalidad es un componente importante y muestra que ciertos meses o 칠pocas del a침o presentan picos o ca칤das en la tasa de inter칠s, posiblemente asociados con din치micas de liquidez o factores econ칩micos espec칤ficos (como ciclos agr칤colas, comerciales o el impacto de eventos globales c칤clicos).
Los picos m치s acentuados y las ca칤das r치pidas indican que la estacionalidad tiene un impacto considerable, con cambios regulares de corto plazo que el Banco de la Rep칰blica puede usar para ajustar la pol칤tica.


* **Trend (Componente de Tendencia):**

La tendencia de largo plazo muestra un ciclo de aumento hacia finales de los a침os 2000, seguido de una disminuci칩n suave en los a침os posteriores. Sin embargo, desde alrededor de 2020, se observa un repunte claro de las tasas.
Este aumento de las tasas a partir de 2020 puede estar relacionado con factores econ칩micos recientes, como la pandemia de COVID-19, el aumento de la inflaci칩n global y las medidas que los bancos centrales, como el BanRep, tomaron para frenar la inflaci칩n y ajustar la pol칤tica monetaria.
El gr치fico sugiere que la tasa de intervenci칩n ha seguido un patr칩n c칤clico a largo plazo, con fases alternas de crecimiento y ca칤da.

* **Remainder (Componente Residual):**

El componente residual muestra las fluctuaciones que no pueden explicarse ni por la tendencia ni por la estacionalidad. Estas variaciones podr칤an deberse a eventos inesperados o choques externos que han afectado la pol칤tica monetaria del pa칤s.
Se observan varios picos de volatilidad, como por ejemplo, alrededor del 2002, 2008-2009 (coincidiendo con la crisis financiera global), y m치s recientemente en torno a 2020, que podr칤a estar relacionado con los efectos econ칩micos de la pandemia.

La volatilidad hacia el final del gr치fico es m치s alta, lo que podr칤a indicar periodos de mayor incertidumbre econ칩mica o choques en los 칰ltimos a침os.


* **Tendencia de tasas crecientes:** El reciente aumento de las tasas de inter칠s refleja probablemente un intento del Banco de la Rep칰blica de controlar la inflaci칩n y mantener la estabilidad macroecon칩mica en medio de un entorno de incertidumbre global.


* **Estacionalidad significativa:** El componente estacional muestra que la pol칤tica monetaria sigue patrones regulares, lo cual puede estar vinculado con las necesidades c칤clicas de liquidez en el mercado. Estos ciclos estacionales parecen estar bien definidos, lo que permite un ajuste m치s predecible de las tasas en el corto plazo.


* **Impacto de choques econ칩micos:** El componente residual sugiere que eventos econ칩micos inesperados han afectado la pol칤tica monetaria, especialmente en periodos de crisis como 2008 y 2020. Estos choques pueden generar fluctuaciones a corto plazo que no son f치cilmente predecibles.


## Estacionariedad

La prueba ADF indica si la serie tiene una ra칤z unitaria (es decir, si no es estacionaria).

```{r echo=FALSE, warning=FALSE}

# Prueba de Dickey-Fuller aumentada
adf_test <- tseries::adf.test(ts_data, alternative = "stationary")

# Mostrar resultado de la prueba ADF
print(adf_test)

```

El resultado del test muestra un valor de -1.15, con un p-valor de 0.9133. Dado que el p-valor es alto (mayor que un nivel de significancia com칰n), sugiere que la serie temporal NO es estacionaria, por lo que podr칤a requerir transformaciones adicionales, como la diferenciaci칩n, para hacerla estacionaria antes de modelarla.


## Diferenciaci칩n

Si una serie no es estacionaria, la diferenciaci칩n la ayuda a volverse estacionaria.

```{r echo=FALSE, warning=FALSE}
# Diferenciaci칩n de la serie
differenced_data <- diff(ts_data)

# Graficar la serie diferenciada
plot(differenced_data, main = "Serie Diferenciada", ylab = "Diferencia de Tasa", xlab = "Tiempo")

```

Al diferenciar la serie de tiempo, se observa en el gr치fico  una serie fluctuante en torno a cero. Esto es una se침al de que la diferenciaci칩n ayud칩 a eliminar la tendencia de la serie original, haciendo que los valores oscilen alrededor de un valor medio estable, lo que suele indicar un proceso estacionario.

## Volver a verificar la Estacionariedad tras la Diferenciaci칩n


Realizar nuevamente el test de Dickey-Fuller sobre la serie diferenciada permite confirmar la estacionariedad alcanzada:
 
 
```{r echo=FALSE, warning=FALSE}

# Prueba de Dickey-Fuller aumentada
adf_test2 <- tseries::adf.test(differenced_data, alternative = "stationary")

# Mostrar resultado de la prueba ADF
print(adf_test2)

```

El resultado del test de Dickey-Fuller aplicado a la serie diferenciada muestra un valor de estad칤stico de -3.0792 y un valor p de 0.1214. Aunque el estad칤stico es m치s bajo que en la serie inicial, el valor p sigue siendo mayor a 0.05, lo que significa que la serie diferenciada podr칤a no ser completamente estacionaria, y podr칤a sea necesario un segundo nivel de diferenciaci칩n o explorar otras transformaciones.


## Autocorrelaci칩n (ACF) y Parcial (PACF)

```{r echo=FALSE, warning=FALSE}

# ACF y PACF de la Serie Diferenciada
par(mfrow = c(1, 2))  
acf(differenced_data, main = "ACF de la Serie Diferenciada")
pacf(differenced_data, main = "PACF de la Serie Diferenciada")

```

* **ACF:** Las barras decrecientes sugieren una estructura de autocorrelaci칩n significativa, especialmente en los primeros rezagos, lo cual es t칤pico en series con dependencia a corto plazo.

* **PACF:**  muestra una ca칤da r치pida despu칠s del primer rezago, lo cual sugiere que un modelo ARIMA de bajo orden podr칤a ser adecuado para capturar la din치mica de la serie diferenciada.



```{r echo=FALSE, warning=FALSE}

# Descomposici칩n de la serie de tiempo
descomposicion2 <- stl(differenced_data, s.window = "periodic")

# Graficar la descomposici칩n
plot(descomposicion2, main = "Descomposicion TS DIFERENCIADA")

```

* **Data:** Se observa que a lo largo de la serie, existen varios picos, y la variabilidad parece aumentar en ciertos puntos. Esto indica que hay per칤odos con comportamiento an칩malo o ruido.

* **Seasonal (Estacional):** La componente estacional muestra una clara periodicidad, con patrones que se repiten consistentemente en intervalos regulares. Esto indica que la serie tiene un comportamiento c칤clico fuerte. Este componente estacional es 칰til para capturar patrones que se repiten cada cierto tiempo.

* **Trend (Tendencia):** La tendencia parece ser suave y muestra algunos cambios a lo largo del tiempo. Aunque la serie fue diferenciada, la tendencia residual indica que a칰n existen fluctuaciones de largo plazo, como un ligero aumento hacia el final de la serie. Esto sugiere que, aunque se haya eliminado una parte de la tendencia inicial mediante la diferenciaci칩n, todav칤a hay un componente de tendencia en los datos.

* **Remainder (Residuo):** Este componente representa la variabilidad no explicada por la estacionalidad ni la tendencia. Se observan varios picos y una dispersi칩n m치s amplia en ciertos puntos de la serie. Esto sugiere que puede haber variaciones aleatorias o anomal칤as en ciertos periodos, especialmente al final, donde los residuos son m치s grandes. La presencia de valores residuales grandes refuerza la idea de que hay eventos impredecibles o ruido en la serie.

En resumen, la serie de tiempo diferenciada a칰n conserva una componente estacional significativa, y la tendencia residual es peque침a pero sigue presente. Los residuos presentan variaciones irregulares, especialmente al final, lo cual podr칤a indicar la necesidad de modelar con m치s precisi칩n estos picos o variabilidad.


# **Definici칩n de Modelos**

## Modelo Arima

A continuaci칩n se probar치n dos alternativas de modelo ARIMA, de acuerdo con los an치lisis realizados previamente, a fin de elegir aquel que se acomode mejor a la serie. 


**Alternativa 1 - c(1, 2, 3) (1, 1, 1):**

* Diferenciaci칩n no estacional (d): Dado que ya se aplic칩 una primera diferenciaci칩n en los datos y todav칤a no es completamente estacionaria, es posible considerar incrementar el par치metro de a 2. 

* Estacionalidad (seasonal): Como existe un patr칩n estacional claro en la serie, conviene incluir una diferenciaci칩n estacional (D = 1) y ajustar los par치metros P y Q para capturar las dependencias estacionales. Se probar치 el modelo con un seasonal = c(1, 1, 1) para incluir un t칠rmino autoregresivo y uno de promedio m칩vil estacional.

* Componentes AR y MA (p y q): Dado que p y q determinan la cantidad de t칠rminos autoregresivos y de promedio m칩vil, conviene probar con valores m치s altos para q y ajustar p de acuerdo con la correlaci칩n en los residuos. Esto puede ayudar a mejorar la precisi칩n del modelo y su capacidad predictiva.

```{r echo=FALSE, warning=FALSE}

# Ajuste del modelo ARIMA - ALTERNATIVA 1
modelo_arima <- Arima(differenced_data, order = c(1, 2, 3), seasonal = c(1, 1, 1))

# Resumen del modelo ajustado
summary(modelo_arima)

# Graficar los residuos para verificar la aleatoriedad
checkresiduals(modelo_arima)

# Pronosticar los pr칩ximos 72 per칤odos (6 a침os)
pronostico <- forecast(modelo_arima, h = 72)

# Graficar el pron칩stico con el eje x adecuado
plot(pronostico, xlab = "A침o", ylab = "Tasa", main = "Pron칩stico de Tasa")

```

* **Par치metros no estacionales**

* p = 1 (un t칠rmino autoregresivo),
* d = 2 (diferenciaci칩n de segundo orden para hacer estacionaria la serie en t칠rminos de tendencia),
* q = 3 (tres t칠rminos de promedio m칩vil).

* **par치metros estacionales*, donde:**

* P = 1 (un t칠rmino autoregresivo estacional),
* D = 1 (diferenciaci칩n estacional),
* Q = 1 (un t칠rmino de promedio m칩vil estacional),

* Los coeficientes y sus errores est치ndar sugieren que la mayor칤a de los t칠rminos son significativos (coeficientes altos en relaci칩n con sus errores est치ndar).


* El test de Ljung-Box eval칰a si los residuos del modelo son independientes (no correlacionados). Con un p-valor de 0.1302, se sugiere que los residuos no tienen autocorrelaci칩n significativa. Esto indica que el modelo est치 capturando bien la estructura de la serie.

* Los resultados muestran que el modelo ARIMA(1,2,3)(1,1,1)[12] es probablemente adecuado para la serie.

* El p-valor del test de Ljung-Box mayor a 0.05 indica que el modelo ha eliminado la mayor칤a de la autocorrelaci칩n en los residuos, lo cual es positivo.


**Alternativa 1 - An치lisis de Residuos**

```{r echo=FALSE, warning=FALSE}

# Normal QQ Plot de los residuos
residuos_diff <- residuals(modelo_arima)
par(mfrow = c(1, 1))  
qqnorm(residuos_diff, main = "Normal QQ Plot de Residuos 1")
qqline(residuos_diff, col = "red")

# Realizar el test de normalidad de Shapiro-Wilk
shapiro_test <- shapiro.test(residuos_diff)
print(shapiro_test)



```

Teniendo en cuenta la prueba de normalidad de Shapiro-Wilk, con un valor de 0.82525, siendo relativamente menor a 1, indica que los residuos no siguen una distribuci칩n normal.

En cuanto a p-value < 2.2e-16, al ser una cifra tan peque침a, se confirma que los residuos no son normales.

Por su parte, en la gr치fica se evidencia un patr칩n en que los residuos tienen colas m치s gruesas que una distribuci칩n normal, lo cual reafirma la posible presencia de outliers o una distribuci칩n sesgada en los datos.


**Alternativa 1 - An치lisis de volatilidad utilizando Garch**

```{r echo=FALSE, warning=FALSE}

# An치lisis de volatilidad utilizando fGarch
garch_model <- garch(residuos_diff, order = c(1, 1))
summary(garch_model)



```

El modelo GARCH(1,1) parece ser adecuado para modelar la volatilidad de residuos_diff, ya que los coeficientes son significativos y el test de Box-Ljung no muestra autocorrelaci칩n en los residuos al cuadrado.

La alta significancia de los coeficientes ARCH (a1) y GARCH (b1) indica que tanto los residuos recientes como la volatilidad pasada influyen en la volatilidad actual.

La prueba de Jarque-Bera sugiere que los residuos no siguen una distribuci칩n normal, lo cual puede indicar la presencia de colas pesadas o asimetr칤a, caracter칤sticas t칤picas en series financieras.

Este modelo GARCH(1,1) es 칰til para capturar los cambios en la volatilidad de la serie residuos_diff. La ausencia de autocorrelaci칩n en los residuos al cuadrado tambi칠n sugiere que el modelo ha capturado adecuadamente la heterocedasticidad de la serie.


**Auto Arima para identificar la Alternativa 2**

```{r echo=FALSE, warning=FALSE}
# Aplicar auto.arima para determinar los par치metros adecuados, incluyendo las diferenciaciones
modelo_auto <- auto.arima(differenced_data)
print(modelo_auto)
```

El modelo ARIMA(1,1,2) se seleccion칩 como el mejor ajuste para differenced_data basado en los valores del AIC, AICc, y BIC. La inclusi칩n de t칠rminos AR y MA sugiere que hay dependencias de corto plazo en la serie, pero el ajuste no es perfecto, dado el tama침o de los errores est치ndar y el valor de sigma^2. Si el objetivo es la predicci칩n, este modelo podr칤a ser una buena base, aunque podr칤an explorarse otros modelos o ajustes adicionales para mejorar la precisi칩n.




**Alternativa 2 - c(1, 1, 2) (1, 1, 0):**


```{r echo=FALSE, warning=FALSE}

# Ajuste del modelo ARIMA OPCI칍N 2
modelo_arima2 <- Arima(differenced_data, order = c(1, 1, 2), seasonal = c(1, 1, 0))
summary(modelo_arima2)
checkresiduals(modelo_arima2)

# Pronosticar los pr칩ximos 72 per칤odos (6 a침os)
pronostico2 <- forecast(modelo_arima2, h = 72)

# Graficar el pron칩stico con el eje x adecuado
plot(pronostico2, xlab = "A침o", ylab = "Tasa", main = "Pron칩stico de Tasa")

```

*Autorregresivo:*
ar1 = 0.9274: Con un valor positivo, indica que existe una relaci칩n directa entre el valor actual de la serie y su valor anterior. Es decir, cuando el valor en el periodo t-1 aumenta, el valor en el periodo actual t tiende a aumentar tambi칠n.

s.e. = 0.0393: Dado que el error est치ndar es bajo, indica que la estimaci칩n de este coeficiente es muy precisa. Esto sugiere que el modelo tiene una gran confianza en la relaci칩n directa entre el valor actual y el valor anterior de la serie temporal.

*Media M칩vil:*
ma1 = -1.6115: El coeficiente negativo para ma1 indica que hubo un error negativo en la predicci칩n en el periodo inmediatamente anterior (t-1). Es decir, el modelo predijo un valor m치s alto que el valor real en el periodo t-1, lo que result칩 en un residuo negativo. Este residuo se ajusta en el modelo a trav칠s del t칠rmino de media m칩vil.
s.e. = 0.0597: El error est치ndar para ma1 es relativamente bajo, lo que sugiere que esta estimaci칩n tiene alta precisi칩n. En otras palabras, el ajuste de la predicci칩n actual basado en el error de la predicci칩n del periodo anterior es bastante confiable.

ma2 = 0.6144: Este coeficiente positivo para ma2 indica que el error positivo en la predicci칩n de dos periodos atr치s (t-2) tiene una relaci칩n directa con el valor actual de la serie; es decir, el modelo sobreestim칩 el valor real dos periodos atr치s, lo que result칩 en un residuo positivo que ahora ajusta la predicci칩n para el periodo actual.
s.e. = 0.0583: Al igual que el error est치ndar de ma1, el error est치ndar de ma2 es bajo, lo que indica que esta estimaci칩n es tambi칠n relativamente precisa.

*Autorregresivo estacional (SAR1):*
sar1 = -0.4744: El coeficiente negativo para sar1 sugiere que existe una relaci칩n inversa entre el valor actual de la serie y el valor de la serie con un rezago estacional de un periodo (es decir, el valor de la serie 12 periodos atr치s). Si el valor de la serie en el periodo t-12 fue alto, el valor en el periodo actual t tender치 a ser m치s bajo. 
s.e. = 0.0620: El error est치ndar para sar1 es relativamente bajo, lo que indica que esta estimaci칩n tambi칠n es bastante precisa y que el modelo tiene una buena confianza en el impacto de la componente estacional.

el modelo ARIMA(1,1,2)(1,1,0) tiene coeficientes precisos para los diferentes componentes (AR, MA y SAR), lo que sugiere que el modelo est치 bien ajustado y que las relaciones capturadas por los coeficientes son confiables.


**Alternativa 2 - An치lisis de residuos**

```{r echo=FALSE, warning=FALSE}

# An치lisis de Residuos Alternativa 2

# Normal QQ Plot de los residuos
residuos_diff2 <- residuals(modelo_arima2)
par(mfrow = c(1, 1))  
qqnorm(residuos_diff2, main = "Normal QQ Plot de Residuos 2")
qqline(residuos_diff2, col = "red")

# Realizar el test de normalidad de Shapiro-Wilk
shapiro_test2 <- shapiro.test(residuos_diff2)
print(shapiro_test)


```


Los resultados del test de Shapiro-Wilk indican que los residuos (residuos_diff) no siguen una distribuci칩n normal.

En cuanto a la gr치fica tambi칠n refleja la No normalidad. La desviaci칩n de los puntos en los extremos sugiere que los residuos tienen colas m치s pesadas de lo que se esperar칤a bajo una distribuci칩n normal. Este resultado es coherente con el Shapiro-Wilk test.


**Alternativa 2 - An치lisis de volatilidad fGarch**

```{r echo=FALSE, warning=FALSE}

# An치lisis de volatilidad utilizando fGarch
garch_model2 <- garch(residuos_diff2, order = c(1, 1))
summary(garch_model2)



```

* El modelo GARCH(1,1) parece capturar correctamente la volatilidad en los residuos, dado que no hay autocorrelaci칩n significativa en los residuos al cuadrado.

* Aunque los residuos no son normales (como muestra la prueba de Jarque-Bera), el modelo es a칰n v치lido, ya que los modelos GARCH no requieren normalidad en los residuos.

*El valor elevado de 洧녪1 (0.71542) indica una alta persistencia en la volatilidad, lo que es caracter칤stico en este tipo de series de tiempo financieras.

En resumen, este modelo GARCH(1,1) parece adecuado para modelar la volatilidad de los residuos, aunque los residuos no sean normales.

**Comparaci칩n de modelos**


```{r echo=FALSE, warning=FALSE}

# Comparar criterios estad칤sticos
cat("Criterios estad칤sticos:\n")
cat("Modelo 1:\n")
cat("AIC:", AIC(modelo_arima), "\n")
cat("BIC:", BIC(modelo_arima), "\n\n")

cat("Modelo 2:\n")
cat("AIC:", AIC(modelo_arima2), "\n")
cat("BIC:", BIC(modelo_arima2), "\n\n")

# An치lisis de residuos para ambos modelos
cat("Test de Ljung-Box para autocorrelaci칩n de residuos:\n")
cat("Modelo 1:\n")
Box.test(residuals(modelo_arima), lag = 20, type = "Ljung-Box")

cat("\nModelo 2:\n")
Box.test(residuals(modelo_arima2), lag = 20, type = "Ljung-Box")

# Test de normalidad para residuos
cat("\nTest de normalidad Shapiro-Wilk:\n")
cat("Modelo 1:\n")
shapiro.test(residuals(modelo_arima))

cat("\nModelo 2:\n")
shapiro.test(residuals(modelo_arima2))

# Calcular m칠tricas de error (MAE, RMSE)
library(forecast)

cat("\nM칠tricas de error en datos de entrenamiento:\n")
cat("Modelo 1:\n")
accuracy(modelo_arima)

cat("\nModelo 2:\n")
accuracy(modelo_arima2)

# Graficar residuos
par(mfrow = c(2, 2))  # Dividir pantalla para gr치ficos

# Residuos Modelo 1
qqnorm(residuals(modelo_arima), main = "QQ Plot Residuos Modelo 1")
qqline(residuals(modelo_arima), col = "red")
plot(residuals(modelo_arima), main = "Residuos Modelo 1", ylab = "Residuos")
acf(residuals(modelo_arima), main = "ACF Residuos Modelo 1")

# Residuos Modelo 2
qqnorm(residuals(modelo_arima2), main = "QQ Plot Residuos Modelo 2")
qqline(residuals(modelo_arima2), col = "red")
plot(residuals(modelo_arima2), main = "Residuos Modelo 2", ylab = "Residuos")
acf(residuals(modelo_arima2), main = "ACF Residuos Modelo 2")

# Graficar y comparar pron칩sticos
par(mfrow = c(1, 1))
plot(pronostico2, xlab = "A침o", ylab = "Tasa", main = "Comparaci칩n de Pron칩sticos")
lines(forecast(modelo_arima, h = 72)$mean, col = "blue", lty = 2)
legend("topleft", legend = c("Modelo 1", "Modelo 2"), col = c("blue", "red"), lty = c(2, 1))



```


A nivel general, 

* ALTERNATIVA  1:  muestra problemas de ajuste. Residuos no normales y autocorrelaci칩n presente. Aunque captura la tendencia, su precisi칩n en los pron칩sticos parece m치s limitada.

* ALTERNATIVA  2:  ofrece un mejor ajuste. residuos m치s cercanos a la normalidad, sin autocorrelaciones significativas, y pron칩sticos con intervalos de confianza m치s ajustados. Esto lo hace preferible para tomar decisiones basadas en predicciones m치s consistentes.


En cuanto al an치lisis de pron칩tico:

La Alternativa 1 (l칤nea azul punteada) y la Alternativa 2 (l칤nea negra continua) ofrecen pron칩sticos similares en cuanto a tendencia, pero ela Alternativa 2 parece ser m치s conservadora, con menores amplitudes en sus intervalos de confianza.

Los intervalos de confianza de la  Alternativa 1  (zonas azules sombreadas) son m치s amplios, indicando mayor incertidumbre, mientras que en la 2 (zonas grises sombreadas) son m치s ajustados, lo que sugiere mayor precisi칩n o menos variabilidad esperada, por tanto la 2 podr칤a ser m치s confiable si se busca menor variabilidad en los pron칩sticos a largo plazo.


**En definitiva, ** la decisi칩n es entonces optar por la Alternativa 2, ya que presenta un mejor comportamiento tanto en el ajuste a los datos como en la calidad de los pron칩sticos.


## Algoritmo de Holt Winter 

Puede manejar la estacionalidad en el conjunto de datos simplemente calculando el valor central y luego sum치ndolo o multiplic치ndolo por la pendiente y la estacionalidad. Solo tenemos que asegurarnos de ajustar el conjunto correcto de par치metros, y tenemos el mejor ajuste. 

Recuerde siempre verificar la eficiencia del modelo utilizando el valor MAPE (error porcentual absoluto medio) o el valor RMSE (error cuadr치tico medio), y la precisi칩n puede depender del problema comercial y el conjunto de datos disponible para entrenar y probar el modelo.


Se observan la tendencia y los ciclos:

```{r echo=FALSE, warning=FALSE}
data2 = data

data2 <- data2 %>%
  mutate(Fecha = as.Date(Fecha), Anio = year(Fecha), Mes = month(Fecha, label = TRUE, abbr = TRUE)) %>%
  select(Anio, Mes, everything())

head(data2)


# Graficar solo l칤neas
plot(data2$Anio, data2$Tasa, type = "l", main = "Grafico con Regresion", xlab = "Anio", ylab = "Tasa")

# Ajustar el modelo de regresi칩n lineal
modelo <- lm(Tasa ~ Anio, data = data2)

# Agregar la l칤nea de regresi칩n al gr치fico
abline(modelo, col = "red")



```
```{r echo=FALSE, warning=FALSE}

# Graficar 
ggplot(data2, aes(x = Mes, y = Anio, fill = Tasa)) +
  geom_tile() +  # Usar geom_tile para crear un gr치fico de calor
  scale_fill_gradient(low = "white", high = "blue") +  # Colores del llenado
  labs(title = "Tasa por A침o y Mes", x = "Mes", y = "A침o") +
  theme_minimal()



```

La gr치fica sugiere una disminuci칩n en la tasa a lo largo del tiempo, con una estabilizaci칩n en niveles bajos en los a침os recientes. Esto podr칤a indicar una mejora en el fen칩meno que se est치 midiendo con la "Tasa", aunque el contexto espec칤fico depender치 de qu칠 represente exactamente esa variable en el an치lisis.

```{r echo=FALSE, warning=FALSE}
# serie_temporal <- ts(data2[["Tasa"]], start = c(min(data2$Anio), 1), frequency = 12)

# Extraer el ciclo de la serie temporal
cicle <- cycle(ts_data)

# Ver los ciclos
print(cicle)

```



```{r echo=FALSE, warning=FALSE}
# boxplot(data2~cycle(data2))

# Crear el boxplot por ciclo (mes) para observar la estacionalidad
boxplot(ts_data ~ cycle(ts_data), 
        xlab = "Mes", ylab = "Tasa", 
        main = "Boxplot de Tasa por Mes")

```

Aunque hay consistencia en la mediana y el rango intercuart칤lico de la tasa a lo largo de los meses, existen valores at칤picos en la segunda mitad del a침o. Esto sugiere que, aunque la tasa general se mantiene estable, en algunos meses espec칤ficos ocurren eventos o circunstancias que resultan en tasas inusualmente altas.


```{r echo=FALSE, warning=FALSE}
# plot(log(airmiles), ylab='log(airmiles)', xlab='Anio', main='Logaritmo de la tasa')

plot(data2$Anio, log(data2$Tasa), type = "l", 
     ylab = "Log(Tasa)", xlab = "A침o", 
     main = "Logaritmo de la Tasa a lo largo del Tiempo")
```

La gr치fica sugiere que la tasa ha sido vol치til a lo largo de los a침os, con periodos de estabilidad relativa intercalados con cambios bruscos.

La ca칤da alrededor de 2020 y el r치pido aumento posterior podr칤an reflejar eventos econ칩micos o circunstancias externas que afectaron la tasa en ese periodo.

Esto fue evidenciado en el AN츼LISIS EXPLORATORIO.


## Modelo Holt-Winter

```{r echo=FALSE, warning=FALSE}
# modelo_HW = HoltWinters(log(airmiles), seasonal = "additive")
# plot(modelo_HW, main = 'Ajuste con Holt-Winters', xlab = 'Anio', ylab='log(airmiles)')
# Crear la serie temporal correctamente
ts_data <- ts(data2$Tasa, start = c(min(data2$Anio), min(data2$Mes)), frequency = 12)


# Aplicar el modelo Holt-Winters a la serie temporal
modelo_HW <- HoltWinters(ts_data)
print(modelo_HW)

# Graficar el ajuste del modelo a los datos hist칩ricos
plot(modelo_HW, main = "Ajuste del Modelo Holt-Winters")

# Pron칩stico con Holt-Winters para los pr칩ximos 12 meses
pronostico_hw <- forecast(modelo_HW, h = 12)

# Graficar el pron칩stico
plot(pronostico_hw, main = "Pronostico Holt-Winters para Tasa")


```



*Par치metro suavizado:*

Alpha (풤 = 0.9409767): Este es el par치metro de suavizado para el componente de nivel. Un valor cercano a 1, como el que est치 arrojando el resultado, indica que el modelo le da gran peso a los datos recientes para estimar el nivel actual de la serie. Esto significa que las observaciones recientes tienen un impacto significativo en la estimaci칩n del nivel.

Beta ( = 0.2941339): Este es el par치metro de suavizado para el componente de tendencia en el modelo de Holt-Winters. Un valor de  moderadamente bajo, como 0.2941339, sugiere que el modelo da un peso relativamente moderado a los cambios en la tendencia. Es decir, el modelo no es extremadamente sensible a las variaciones en la tendencia, pero sigue siendo capaz de capturarlas de manera significativa. Con este valor, el modelo ajusta la tendencia de forma m치s suave y gradual, lo que implica que no tiene una sobrereacci칩n ante cambios recientes en la direcci칩n de los datos.

Gamma (풥 = 1): Este es el par치metro de suavizado para el componente estacional. Un valor de 풥 = 1 sugiere que el modelo da completo peso a los componentes estacionales previos en la serie.


```{r echo=FALSE, warning=FALSE}
plot(fitted(modelo_HW), main='Descomposicion con HW', xlab='Anio', ylab='log(airmiles)')
```


La tendencia ascendente en el nivel y la tendencia hacia el final del per칤odo (2025) sugiere que LA TASA est치 experimentando un crecimiento continuo.

La componente estacional muestra ciclos regulares bien definidos, lo que puede ser 칰til para predicciones estacionales precisas.

El modelo Holt-Winters parece ajustarse adecuadamente a la serie, capturando tanto las fluctuaciones estacionales como la tendencia de largo plazo.



**Se predice el m칠todo Holt Winters**

```{r echo=FALSE, warning=FALSE}
pred = predict(modelo_HW, 6, prediction.interval = TRUE)
pred
```

```{r echo=FALSE, warning=FALSE}
plot(modelo_HW, pred)
```



## Metodolog칤a Box Jenkins

Dentro de los pasos a seguir, tenemos:


1. Visualizar la serie.

2. Transformarla en estacionaria.

3. Graficar ACF - PACF, escoger los par치metros.

4. Construir el modelo ARIMA.

5. Hacer la predicci칩n.


Los pasos anteriores ya hab칤an sido previamente incorporados en instancias anteriores del an치lisis bajo otros modelo o metodolog칤as, sin embargo, para fines de aplicar el m칠todo Box Jenkins realizaremos nuevamente el proceso y procedemos a calcular el punto de cambio de la media de la serie de tiempo inicial:

```{r echo=FALSE, warning=FALSE}

# Detectar punto de cambio en la media 
mval <- cpt.mean(ts_data, method = "AMOC")
cpts(mval)


```
Podemos identificar que sobre la serie original se encuentran 276 puntos de cambio de media.


```{r echo=FALSE, warning=FALSE}

# Graficar la serie con el punto de cambio resaltado
plot(mval, type = "l", cpt.col = "blue", xlab = "칈ndice de Tiempo", cpt.width = 4, 
     main = "Punto de Cambio en la Media")


```

Procedemos con el c치lculo de la cantidad de diferenciaciones requeridas para hacer la serie estacionaria,en t칠rminos de media. Este an치lisis es crucial dentro del marco de la metodolog칤a Box-Jenkins, ya que el modelo ARIMA requiere que la serie sea estacionaria. Se observa que se requieren 2 diferenciaciones: 

```{r echo=FALSE, warning=FALSE}

ndiffs(ts_data)
differenced_data2 <- diff(differenced_data) #se genera la segunda diferenciaci칩n sobre differenced_data la cual ya era una diferenciaci칩n de la serie original ts_data.

```

Al correr nuevamente el c칩digo de punto de cambio de media (con **AMOC**)sobre la serie ya diferenciada 2 veces, el resultado es 0, indicando que no se ha detectado ning칰n cambio significativo en la media de dicha serie.

Esto se debe a que al diferenciar la serie, se eliminan componentes como tendencia y cambios en la media, lo que puede hacer que la serie parezca m치s "estable" en t칠rminos de media.


Incluso probando el m칠todo de cambio **PELT**, que es m치s flexible y busca m칰ltiples puntos de cambio, el resultado sobre la serie diferenciado es 0, indicando que no se detectaron puntos de cambio significativos en la media de la serie de tiempo.

```{r echo=FALSE, warning=FALSE}

# Detectar punto de cambio en la media con AMOC
mval <- cpt.mean(differenced_data2, method = "AMOC")
cpts(mval)


mval_varios <- cpt.mean(differenced_data2, method = "PELT") # Detecta m칰ltiples cambios
cpts(mval_varios)


```

A continuaci칩n usarmos la funci칩n **tso** para identificar valores at칤picos en la serie de tiempo diferenciada (2 veces):


```{r echo=FALSE, warning=FALSE}


# Convertir differenced_data2 a un objeto de serie de tiempo con frecuencia 12 (pq la serie es mensual. 1 es si es diaria)

dat.ts <- ts(differenced_data2, frequency = 12)

# Detectar outliers en la serie diferenciada
data.ts.outliers <- tso(dat.ts, maxit.iloop = 50, maxit.oloop = 10)

# Mostrar los resultados de los outliers detectados
print(data.ts.outliers)
plot(data.ts.outliers)

```

* **An치lisis de outliers:**

El an치lisis de outliers usa un modelo ARIMA para ajustar la serie original y detectar los puntos at칤picos. En este caso, el modelo identificado es un ARIMA(1,0,1), lo que indica:

AR(1): Existe una correlaci칩n significativa con el valor inmediatamente anterior.
MA(1): Hay un efecto de ruido blanco ajustado con una media m칩vil de orden 1.
Diferenciaci칩n (0): La serie no fue diferenciada adicionalmente.

El modelo incluye los efectos de los outliers y ajusta la serie eliminando estas anomal칤as para capturar patrones m치s consistentes.


* **Eventos espec칤ficos en las fechas de los outliers:**

LS183 y LS190 (16to a침o, febrero y octubre) indican eventos que cambiaron el nivel de la serie. Esto puede ser consecuencia de eventos externos como pol칤ticas, cambios econ칩micos o errores de registro.
Los cambios temporales (e.g., TC297) reflejan eventos transitorios.

Efectos significativos: LS305 (26:05) y TC297 (25:09) tienen impactos muy fuertes y requerir칤a investigarse a profundidad para identificar causas espec칤ficas.



* **Gr치fico**

En la parte superior del gr치fico se observan los puntos rojos que identifica d칩nde se encuentran los outliers. La l칤nea azul muestra la serie original, mientras que la gris es la ajustada (sin los efectos de los outliers).

En la parte inferior del gr치fico se muestra la magnitud de los impactos de cada outlier en la serie.



Se procede a aplicar el test de Dickey Fuller sobre la serie doblemente diferenciada:

```{r echo=FALSE, warning=FALSE}


adf.test(differenced_data2)

```



Se procede a aplicar an치lisis ACF y PACF sobre la serie doblemente diferenciada:

```{r echo=FALSE, warning=FALSE}
# Graficar ACF y PACF
par(mfrow = c(1, 2)) # Configurar para dos gr치ficos lado a lado
acf(differenced_data2, main = "Autocorrelaci칩n (ACF)")
pacf(differenced_data2, main = "Autocorrelaci칩n Parcial (PACF)")

```

* **ACF (Autocorrelaci칩n):**
Observamos un rezago significativo en el primer lag (1), que sobresale de los l칤mites de confianza. Esto sugiere un componente MA(1) (promedio m칩vil de orden 1). A partir del segundo rezago, las autocorrelaciones caen r치pidamente, lo que refuerza la hip칩tesis de un modelo MA de bajo orden.


* **PACF (Autocorrelaci칩n Parcial):**
El PACF muestra un rezago significativo en el primer lag (1), y los rezagos siguientes se reducen gradualmente. Esto indica que podr칤a haber un componente AR(1) (autoregresivo de orden 1). Los rezagos subsiguientes no parecen ser significativos, lo que tambi칠n respalda la hip칩tesis de un modelo AR de bajo orden.





```{r echo=FALSE, warning=FALSE}

modelo_autoarima <- auto.arima(differenced_data2, seasonal = FALSE)

# Resumen del modelo ajustado
summary(modelo_autoarima)

# Graficar el ajuste del modelo
plot(forecast(modelo_autoarima), main = "Pron칩stico con auto.arima")

# An치lisis de residuos
checkresiduals(modelo_autoarima)


```

* **Modelo Ajustado: ARIMA(1,0,2):**

El modelo seleccionado por auto.arima es un ARIMA(1,0,2) sin estacionalidad.


- p = 1: Un t칠rmino autoregresivo.
- d = 0: No se aplic칩 diferenciaci칩n adicional porque la serie ya es estacionaria.
- q = 2: Dos t칠rminos de media m칩vil.
- seasonal = FALSE: No se incluyeron componentes estacionales, lo cual parece adecuado dado el comportamiento de la serie diferenciada.


* **Gr치fica del Pron칩stico:**

La l칤nea azul representa el pron칩stico central. Las bandas grises representan los intervalos de confianza del 80% y 95%. Dado que las bandas se ensanchan a medida que avanzan los per칤odos, esto refleja un aumento en la incertidumbre del pron칩stico.


* **An치lisis de Residuos (checkresiduals)**

- En este caso, los residuos no presentan una tendencia obvia ni autocorrelaci칩n fuerte, lo cual es un buen indicador.

- Dado que la mayor칤a de los puntos caen dentro de los l칤mites de significancia (aproximadamente un nivel de confianza del 95%), no parece haber autocorrelaci칩n significativa, lo que indica que el modelo captura adecuadamente las dependencias temporales.

- El histograma muestra una distribuci칩n aproximadamente normal con una media cercana a cero, lo cual es importante para validar la aplicabilidad del modelo ARIMA.

* **Prueba de Ljung-Box (p-valor: 0.3103)**

Este valor es mayor que 0.05, lo que significa que no podemos rechazar la hip칩tesis nula, es decir que no hay evidencia de autocorrelaci칩n en los residuos, lo cual es un indicador de que el modelo ARIMA ajusta bien la serie.


* **Pron칩stico**

```{r echo=FALSE, warning=FALSE}

# Generar pron칩sticos para los pr칩ximos 12 per칤odos
horizonte <- 6
pronostico <- forecast(modelo_autoarima, h = horizonte)

# Convertir el pron칩stico en una tabla (data frame)
tabla_pronostico <- data.frame(
  Fecha = seq(from = as.Date("2024-11-01"), by = "month", length.out = horizonte),  # Fechas desde noviembre 2024
  Pronostico = as.numeric(pronostico$mean),           # Valores pronosticados
  Limite_Inferior_80 = as.numeric(pronostico$lower[, 1]),  # L칤mite inferior 80%
  Limite_Superior_80 = as.numeric(pronostico$upper[, 1]),  # L칤mite superior 80%
  Limite_Inferior_95 = as.numeric(pronostico$lower[, 2]),  # L칤mite inferior 95%
  Limite_Superior_95 = as.numeric(pronostico$upper[, 2])   # L칤mite superior 95%
)

# Mostrar la tabla
print(tabla_pronostico)



```

Es importante considerar que los datos del pron칩stico est치n en escala pues la serie tiene 2 diferenciaciones, por tanto se procede a convertir a escala original:

```{r echo=FALSE, warning=FALSE}
# 칔ltimos valores originales conocidos
ultimo_valor_original <- tail(ts_data, 1)  # 칔ltimo valor de la serie original
ultimo_valor_diferenciado <- tail(differenced_data, 1)  # 칔ltimo valor de la serie diferenciada una vez

# Revertir la segunda diferenciaci칩n
forecast_level1 <- cumsum(pronostico$mean) + rep(ultimo_valor_diferenciado, length(pronostico$mean))

# Revertir la primera diferenciaci칩n
forecast_final <- cumsum(forecast_level1) + rep(ultimo_valor_original, length(forecast_level1))

# Crear tabla con los valores des-diferenciados
tabla_pronostico_ARIMA_original <- data.frame(
  Fecha = seq(from = as.Date("2024-11-01"), by = "month", length.out = horizonte),
  Pronostico = forecast_final
)

# Mostrar resultados
print(tabla_pronostico_ARIMA_original)



```


## Modelo Prophet

Para trabajar este modelo, partimos de la data original pues el modelo Prophet no requiere que la serie  sea diferenciada previamente porque internamente utiliza una combinaci칩n de m칠todos que manejan las tendencias y estacionalidades de manera expl칤cita, evitando la necesidad de transformar la serie para hacerla estacionaria, como se hace en modelos como ARIMA. 


```{r echo=FALSE, warning=FALSE}

data3 <- data

data3 <- data3 %>%
  arrange(Fecha)  # Ordena las fechas


data3$Fecha <- as.Date(data3$Fecha, format = "%Y-%m-%d")




# Renombrar las columnas para prophet
prophet_data <- data.frame(
  ds = data3$Fecha,  # Fecha en la columna 'ds'
  y = data3$Tasa  # La columna 'Tasa' en 'y'
)

# Crear y ajustar el modelo
model <- prophet(prophet_data)

# Crear un DataFrame para 6 meses hacia adelante sin incluir las fechas hist칩ricas
future <- make_future_dataframe(model, periods = 6, freq = "month", include_history = FALSE)

# Generar las predicciones
forecast <- predict(model, future)

# Mostrar las primeras filas de las predicciones
head(forecast[, c("ds", "yhat", "yhat_lower", "yhat_upper")])

```


* Valores centrales **(yhat)** Son las predicciones para la variable Tasa, desde noviembre de 2024 hasta abril de 2025. Por ejemplo, para noviembre de 2024, se predice que la tasa ser치 de aproximadamente 10.03%; los valores aumentan ligeramente hacia principios de 2025, lo que podr칤a indicar una tendencia al alza.


* Los intervalos de confianza **(yhat_lower y yhat_upper)**, indican la incertidumbre asociada a cada predicci칩n.
Por ejemplo, para noviembre de 2024, el modelo predice que la tasa podr치 oscilar entre 6.71 y 13.31 con un nivel de confianza alto. Dado que los intervalos son amplios, sugiere que hay incertidumbre considerable en las proyecciones a futuro (esto puede originarse por una alta volatilidad en los datos hist칩ricos).


* Se evidencia tambi칠n que las predicciones para fechas m치s cercanas, como noviembre y diciembre de 2024, tienen menor incertidumbre (IC m치s estrecho) en comparaci칩n con fechas m치s lejanas, como marzo y abril de 2025. Esto es esperado porque la precisi칩n del modelo suele disminuir con el tiempo.



```{r echo=FALSE, warning=FALSE}


# Graficar predicciones
plot(model, forecast)
```

* Los puntos negros representan los datos hist칩ricos de la serie temporal. La gr치fica muestra una tendencia con picos y valles notables, lo que podr칤a indicar una serie con alta variabilidad (esto sustenta lo mencionado anteriormente) y posiblemente alg칰n patr칩n c칤clico o estacionalidad.

* En la parte derecha de la gr치fica, se observa una l칤nea azul que representa la predicci칩n del modelo para el futuro cercano.

* Las 치reas sombreadas en azul alrededor de las predicciones representan los intervalos de confianza del modelo, que indican el rango dentro del cual es m치s probable que se encuentren los valores reales. Estos intervalos son m치s amplios en la predicci칩n debido a la incertidumbre inherente a los modelos predictivos.

* El modelo parece ajustarse bien a los datos hist칩ricos y proporciona predicciones con una incertidumbre razonable. Se podr칤a inferir que los valores futuros tienen una probabilidad de mantenerse en el rango predicho, sujeto a factores externos.



```{r echo=FALSE, warning=FALSE}


# Graficar los componentes del modelo
prophet_plot_components(model, forecast)


```

Esta gr치fica muestra los componentes del modelo generado con Prophet, descomponiendo la serie temporal en tendencia (trend) y estacionalidad anual (yearly).

* **Tendencia:** El gr치fico muestra c칩mo evoluciona la tendencia general a lo largo del tiempo (noviembre a abril).
Se observa un incremento gradual en los valores a medida que avanza el tiempo. Esto indica una tendencia positiva sostenida en la serie temporal, lo que puede implicar crecimiento o recuperaci칩n en el fen칩meno estudiado.

La banda sombreada alrededor de la l칤nea representa el intervalo de confianza del modelo, indicando la incertidumbre asociada a las predicciones. En este caso, la incertidumbre es baja, ya que la banda es estrecha.


* **Estacionalidad anual:** Este gr치fico captura patrones repetitivos que ocurren dentro de un a침o.
Se observan picos y valles a lo largo del a침o, lo que sugiere que el fen칩meno presenta una fuerte estacionalidad.

Los picos indican que los valores tienden a ser m치s altos en ese mes, mientras que los valles muestran que los valores disminuyen en ese per칤odo.Entre julio y octubre, se observa una fluctuaci칩n m치s moderada.

* En resumen, el modelo identifica una combinaci칩n de una tendencia creciente y un patr칩n de estacionalidad anual, lo que es clave para entender y predecir el comportamiento del fen칩meno a futuro.



## Redes Neuronales


**Preparaci칩n de los Datos**

A continuaci칩n vamos a normalizar la columna Tasa y dividir los datos en conjuntos de entrenamiento y prueba. 

```{r echo=FALSE, warning=FALSE}

data2 = data

# Normalizaci칩n de la columna 'Tasa' entre 0 y 1
normalize <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

data2$Tasa_norm <- normalize(data2$Tasa)

# Dividir los datos en entrenamiento (75%) y prueba (25%)

set.seed(123)
train_indices <- sample(1:nrow(data2), 0.75 * nrow(data2))
train_data <- data2[train_indices, ]
test_data <- data2[-train_indices, ]

```



```{r echo=FALSE, warning=FALSE}
# Calcular el origen de las fechas
fecha_max <- as.Date("2024-10-01")  # 칔ltima fecha conocida
dias_max <- 19905                  # Valor num칠rico de la 칰ltima fecha

# Calcular el origen restando los d칤as
fecha_origen <- fecha_max - dias_max

# Convertir la columna Fecha en formato Date
test_data$Fecha <- as.Date(test_data$Fecha, origin = as.character(fecha_origen))



```


**Modelo ELMAN**

A continuaci칩n se entrena una red neuronal de tipo Elman, con el fin de predecir la Tasa, esto a trav칠s del uso de un conjunto de datosd e entrenamiento.

Para esto, se realiza el siguiente proceso:

* Se prepara la entrada y salida del modelo utilizando los datos normalizados.
* Se crea y entrena la red Elma con 10 neuronas en la capa oculta, una tasa de aprendizaje del 5% y un m치ximo de 1.000 iteraciones.

Los valores predichos por el modelo se encuentran en un rango cercano entre 11.79 y 13.31. Esto sugiere que el modelo ha aprendido un patr칩n en los datos de entrada y salida, y las predicciones son coherentes dentro de un rango esperado.

```{r echo=FALSE, warning=FALSE}

# Preparar los datos de entrada y salida
train_input <- as.matrix(train_data$Tasa_norm)
train_output <- as.matrix(train_data$Tasa_norm)

# Crear y entrenar la red Elman
set.seed(123)
elman_model <- elman(
  x = train_input, 
  y = train_output, 
  size = c(10),  # 10 neuronas en la capa oculta
  learnFuncParams = c(0.05),  # Tasa de aprendizaje
  maxit = 1000,  # M치ximo n칰mero de iteraciones
  linOut = TRUE  # Salida lineal para problemas de regresi칩n
)

# Predicciones en el conjunto de prueba
test_input <- as.matrix(test_data$Tasa_norm)
predictions_elman <- predict(elman_model, test_input)

# Desnormalizar las predicciones
denormalize <- function(x, original) {
  x * (max(original) - min(original)) + min(original)
}


predictions_elman_desnorm <- denormalize(predictions_elman, data2$Tasa)


test_data$Predicciones_Elman <- predictions_elman_desnorm


# Extraer solo las columnas "Fecha" y "Predicciones_Elman"
predicciones_con_fecha <- test_data[, c("Fecha", "Predicciones_Elman")]

# Ver el resultado
head(predicciones_con_fecha)


```

El c칩digo a continuaci칩n, eval칰a el rendimiento del modelo Elman al calcular la correlaci칩n entre las predicciones realizadas por el modelo y los valores reales del conjunto de prueba. Utilizando la funci칩n cor(), se obtiene el coeficiente de correlaci칩n de Pearson, que mide la relaci칩n lineal entre las predicciones y los valores observados. 

Al obtener un resultado de 0.9999664, y al ser un valor muy cercano a 1, se entiende como una alta correlaci칩n entre las predicciones del modelo y los datos reales. Por lo tanto, el modelo de redes neuronales de Elman est치 prediciendo adecuadamente los valores en el conjunto de prueba.



```{r echo=FALSE, warning=FALSE}

# Evaluaci칩n
actuals <- test_data$Tasa
print(cor(predictions_elman, actuals))  # Correlaci칩n entre predicciones y valores reales

```



**Predicciones futuras ELMAN:**

Con el siuguiente c칩digo se realiza una predicci칩n de valores futuros utilizando el modelo previo de Elman. Se crea una secuencia de fechas de seis meses a partir de noviembre de 2024. Luego, se toma el 칰ltimo valor de las predicciones no desnormalizadas para usarlo como entrada inicial para generar las predicciones futuras. Posteriormente el c칩digo ejecuta un ciclo que para cada fecha futura predice el siguiente valor con el modelo de Elman, actualizando la entrada para la siguiente predicci칩n con el valor pronosticado previamente. 

Teniendo en cuenta el resultado de Elman, se tendr칤a un crecimiento gradual en la tasa,para los siguientes seis meses (de noviembre 2024 a abril 2025); pasando de 23.90% a 24.13% respectivamente.

```{r echo=FALSE, warning=FALSE}

# Crear una secuencia de fechas futuras. 6 meses a partir de noviembre de 2024
fechas_futuras <- seq(as.Date("2024-11-01"), by = "month", length.out = 6)

# Obtener el 칰ltimo valor de las predicciones no desnormalizadas
ultimo_valor_no_desnormalizado <- predictions_elman[length(predictions_elman)]

# Crear una matriz con la 칰ltima predicci칩n como entrada inicial
input_futuro <- as.matrix(c(ultimo_valor_no_desnormalizado))

# Inicializar un vector para almacenar las predicciones futuras
predicciones_futuras <- numeric(length(fechas_futuras))

# Generar predicciones futuras
for (i in 1:length(fechas_futuras)) {
  # Predecir el siguiente valor usando el modelo Elman
  predicciones_futuras[i] <- predict(elman_model, input_futuro)
  
  # Actualizar la entrada para la siguiente predicci칩n
  input_futuro <- as.matrix(predicciones_futuras[i])
  
  # Imprimir cada predicci칩n futura para revisar el proceso
  cat("Predicci칩n para", fechas_futuras[i], ": ", predicciones_futuras[i], "\n")
}

# Desnormalizar las predicciones futuras
predicciones_futuras_desnormalizadas <- denormalize(
  x = predicciones_futuras,
  original = data2$Tasa
)

# Crear el dataframe con las predicciones futuras desnormalizadas
data_futuro_desnormalizado <- data.frame(
  Fecha = fechas_futuras,
  Predicciones_Elman_Desnorm = predicciones_futuras_desnormalizadas
)

# Mostrar las predicciones futuras desnormalizadas
print(data_futuro_desnormalizado)



```


A continuaci칩n se muestra la gr치fica, en donde se puede visualizar la predicci칩n de la tasa para los seis meses.

```{r echo=FALSE, warning=FALSE}


ggplot(data_futuro_desnormalizado, aes(x = Fecha, y = Predicciones_Elman_Desnorm)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  labs(title = "Pron칩stico de la Tasa con Red Elman",
       x = "Fecha",
       y = "Predicci칩n de Tasa") +
  theme_minimal()

```

Integrar los datos con las predicciones pasadas


```{r echo=FALSE, warning=FALSE}

# Verificar los nombres de las columnas en ambos dataframes
colnames(data_futuro_desnormalizado)
colnames(predicciones_con_fecha)

# Renombrar las columnas para que coincidan
colnames(data_futuro_desnormalizado)[colnames(data_futuro_desnormalizado) == "Predicciones_Elman_Desnorm"] <- "Predicciones_Elman"
colnames(predicciones_con_fecha)[colnames(predicciones_con_fecha) == "Predicciones_Elman"] <- "Predicciones_Elman"

# Combinar los datos
data_completo <- rbind(data_futuro_desnormalizado, predicciones_con_fecha)

# Convertir la columna Fecha a tipo Date y ordenar los datos por fecha
data_completo$Fecha <- as.Date(data_completo$Fecha)
data_completo <- data_completo[order(data_completo$Fecha, decreasing = TRUE), ]

# Imprimir los registros m치s recientes
head(data_completo, 12)



```

A continuaci칩n se muestra el gr치fico con los datos pasados as칤 como con las predicciones:

```{r echo=FALSE, warning=FALSE}

ggplot(data_completo, aes(x = Fecha, y = Predicciones_Elman)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  labs(title = "Predicciones pasadas y pron칩stico futuro",
       x = "Fecha",
       y = "Predicci칩n de Tasa") +
  theme_minimal()


```




**Modelo JORDAN**

El modelo de red neuronal de tipo Jordan, permite captar patrones temporales y secuenciales. En este caso, la red se entrena utilizando los datos de entrada (train_input) y las salidas deseadas (train_output), con 5 neuronas en la capa oculta y una tasa de aprendizaje de 10%. El entrenamiento se realiza en un m치ximo de 500 iteraciones. Despu칠s de entrenar el modelo, se realizan predicciones sobre el conjunto de prueba (test_input), que luego se desnormalizan utilizando los valores de la tasa de la serie temporal original.

El resultado de  0.9994467, muestra que el modelo es muy eficiente para predecir las tasas.


```{r echo=FALSE, warning=FALSE}

# Crear y entrenar la red Jordan
set.seed(123)
jordan_model <- jordan(
  x = train_input, 
  y = train_output, 
  size = c(5),  # 5 neuronas en la capa oculta
  learnFuncParams = c(0.1),  # Tasa de aprendizaje
  maxit = 500,  # M치ximo n칰mero de iteraciones
  linOut = TRUE  # Salida lineal para problemas de regresi칩n
)

# Predicciones en el conjunto de prueba
predictions_jordan <- predict(jordan_model, test_input)

# Desnormalizar las predicciones
predictions_jordan_desnorm <- denormalize(predictions_jordan, data2$Tasa)

# Crear un DataFrame con las predicciones y las fechas correspondientes
predicciones_con_fechas_jordan <- data.frame(
  Fecha = test_data$Fecha,               # Fechas correspondientes
  Predicci칩n_Jordan = predictions_jordan_desnorm  # Predicciones de Jordan
)

# Ver las primeras filas para verificar
head(predicciones_con_fechas_jordan)



```

```{r echo=FALSE, warning=FALSE}

# Evaluaci칩n
print(cor(predictions_jordan_desnorm, actuals))  # Correlaci칩n entre predicciones y valores reales


```


**Predicciones futuras JORDAN:**

Con el modelo Jordan, se muestra para las predicciones futuras una disminuci칩n de la tasa, pasando de 21.84% a 17.16% en seis meses.

```{r echo=FALSE, warning=FALSE}
# Crear una secuencia de fechas futuras (6 meses desde noviembre de 2024)
fechas_futuras <- seq(as.Date("2024-11-01"), by = "month", length.out = 6)

# Normalizar el 칰ltimo valor de las predicciones (usando min y max de la columna Tasa de data2)
normalize_single_value <- function(x, min_value, max_value) {
  (x - min_value) / (max_value - min_value)
}

# Obtener el 칰ltimo valor desnormalizado de las predicciones de Jordan
ultimo_valor_desnormalizado <- predictions_jordan_desnorm[length(predictions_jordan_desnorm)]

# Normalizar el 칰ltimo valor usando el min y max de la columna Tasa de data2
ultimo_valor_normalizado <- normalize_single_value(ultimo_valor_desnormalizado, min(data2$Tasa), max(data2$Tasa))

# Crear una matriz con la 칰ltima predicci칩n normalizada como entrada inicial
input_futuro <- as.matrix(c(ultimo_valor_normalizado))

# Inicializar un vector para almacenar las predicciones futuras
predicciones_futuras_jordan <- numeric(length(fechas_futuras))

# Generar las predicciones futuras
for (i in 1:length(fechas_futuras)) {
  # Predecir el siguiente valor usando el modelo Jordan
  predicciones_futuras_jordan[i] <- predict(jordan_model, input_futuro)
  
  # Actualizar la entrada para el siguiente paso
  input_futuro <- as.matrix(predicciones_futuras_jordan[i])
  
  # Imprimir cada predicci칩n futura
  cat("Predicci칩n para", fechas_futuras[i], ": ", predicciones_futuras_jordan[i], "\n")
}

# Desnormalizar las predicciones futuras
predicciones_futuras_jordan_desnorm <- denormalize(
  x = predicciones_futuras_jordan,
  original = data2$Tasa
)

# Crear el dataframe con las predicciones futuras desnormalizadas
data_futuro_jordan <- data.frame(
  Fecha = fechas_futuras,
  Predicci칩n_Jordan = predicciones_futuras_jordan_desnorm
)

# Ver las predicciones futuras
print(data_futuro_jordan)


```

```{r echo=FALSE, warning=FALSE}
# Gr치fico con las predicciones futuras para el modelo Jordan
ggplot(data_futuro_jordan, aes(x = Fecha, y = Predicci칩n_Jordan)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  labs(title = "Pron칩stico de la Tasa con Red Jordan",
       x = "Fecha",
       y = "Predicci칩n de Tasa") +
  theme_minimal()



```

Similar al modelo Elman, tambi칠n se evidencia un salto en la tasa, correspondiente a los meses de octubre a noviembre del 2024.



```{r echo=FALSE, warning=FALSE}



# Verificar los nombres de las columnas en ambos dataframes
colnames(data_futuro_jordan) # Este es el dataframe con las predicciones futuras de Jordan
colnames(predicciones_con_fechas_jordan) # Este es el dataframe con las predicciones pasadas de Jordan

# Renombrar las columnas para que coincidan
colnames(data_futuro_jordan)[colnames(data_futuro_jordan) == "Predicci칩n_Jordan"] <- "Predicciones_Jordan"
colnames(predicciones_con_fechas_jordan)[colnames(predicciones_con_fechas_jordan) == "Predicci칩n_Jordan"] <- "Predicciones_Jordan"

# Combinar los datos (predicciones futuras y pasadas de Jordan)
data_completo_jordan <- rbind(data_futuro_jordan, predicciones_con_fechas_jordan)

# Convertir la columna Fecha a tipo Date y ordenar los datos por fecha
data_completo_jordan$Fecha <- as.Date(data_completo_jordan$Fecha)
data_completo_jordan <- data_completo_jordan[order(data_completo_jordan$Fecha, decreasing = TRUE), ]

# Imprimir los registros m치s recientes
head(data_completo_jordan, 12)





```


```{r echo=FALSE, warning=FALSE}

# Graficar las predicciones pasadas y pron칩stico futuro para el modelo Jordan
ggplot(data_completo_jordan, aes(x = Fecha, y = Predicciones_Jordan)) +
  geom_line(color = "blue") +               # L칤nea para las predicciones
  geom_point(color = "red") +               # Puntos para las predicciones
  labs(title = "Predicciones pasadas y pron칩stico futuro con Red Jordan",
       x = "Fecha",
       y = "Predicci칩n de Tasa") +           # Etiquetas de los ejes
  theme_minimal()                           # Estilo minimalista



```


**Comparaci칩n de Resultados de ambas Redes**

El resultado a continuacio췂n muestra una comparaci칩n entre las predicciones generadas por los modelos anteriormente realizados: Elman y Jordan. Las predicciones de ambos modelos se acercan a los valores reales, aunque con algunas diferencias notables. Por ejemplo, en las fechas m치s recientes como octubre y septiembre de 2024, ambas predicciones (Elman y Jordan) est치n muy cerca de los valores reales (11.75), pero el modelo Elman presenta un ligero mejor ajuste con valores de 11.790453 y 11.789933, respectivamente, en comparaci칩n con los valores del modelo Jordan, que son 11.815554 y 11.799799. En fechas anteriores, como en diciembre de 2023, los dos modelos tambi칠n muestran predicciones bastante cercanas entre s칤, con ligeras variaciones, siendo el modelo Elman m치s cercano al valor real (13.300097 frente a 13.274618). A lo largo de las fechas m치s antiguas, ambas predicciones siguen una tendencia similar, pero con peque침as diferencias, lo que sugiere que el modelo Elman tiende a ajustarse de manera m치s precisa a los datos reales en comparaci칩n con el modelo Jordan, aunque ambos modelos muestran un rendimiento aceptable en la mayor칤a de los casos.


```{r echo=FALSE, warning=FALSE}

# Crear un DataFrame con los resultados
prediction_table <- data.frame(
  Fecha = test_data$Fecha,                    # Fechas correspondientes
  Actual = actuals,                           # Valores reales
  Predicci칩n_Elman = predicciones_con_fecha$Predicciones_Elman,  # Predicciones de Elman 
  Predicci칩n_Jordan = predicciones_con_fechas_jordan$Predicciones_Jordan     # Predicciones de Jordan
)

# Mostrar las primeras filas de la tabla
head(prediction_table)

# Imprimir toda la tabla 
print(prediction_table)



```

A continuaci칩n, se visualiza una gr치fica con las predicciones comparativas entre los modelos Elman y Jordan.

```{r echo=FALSE, warning=FALSE}
library(ggplot2)

# Crear un DataFrame para comparar
results <- data.frame(
  Fecha = test_data$Fecha,               # Fechas correspondientes
  Actual = actuals,                      # Valores reales
  Elman = predicciones_con_fecha$Predicciones_Elman,             # Predicciones de Elman
  Jordan = predicciones_con_fechas_jordan$Predicciones_Jordan            # Predicciones de Jordan
)

# Verificar que no hay NA o diferencias en las longitudes
summary(results)

# Gr치fico
ggplot(results, aes(x = Fecha)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Elman, color = "Elman")) +
  geom_line(aes(y = Jordan, color = "Jordan")) +
  labs(title = "Comparaci칩n de predicciones", 
       y = "Tasa", 
       color = "Leyenda") +
  theme_minimal()





```
# **Conclusiones Finales**

La Tasa de Intervenci칩n del Banco de la Rep칰blica constituye un indicador clave de la pol칤tica monetaria colombiana, siendo influenciada por decisiones estrat칠gicas para estabilizar la inflaci칩n y el valor de la moneda. Su comportamiento combina tendencias, estacionalidad, y fluctuaciones impredecibles asociadas con eventos externos o decisiones abruptas del Banco Central.

Con el prop칩sito de entender mejor el comportamiento hist칩rico de la serie y de probar la capacidad predictiva de diversos modelos, se llev칩 a cabo un an치lisis exploratorio y se elaboraron los siguientes modelos proyectivos:

* ARIMA (AutoRegressive Integrated Moving Average)
* Holt-Winters (Descomposici칩n de estacionalidad y suavizamiento exponencial)
* Prophet (Modelo ajustable de tendencia y estacionalidad desarrollado por Meta)
* Redes Neuronales (Elman y Jordan)

El an치lisis se bas칩 en datos mensuales desde 1999 hasta 2024, abarcando un periodo extenso que incluye diversas din치micas econ칩micas y cambios estructurales en el pa칤s.



**Comparaci칩n Global de Modelos**


```{r echo=FALSE, message=FALSE, warning=FALSE}

pronostico_hw = pred
pronostico_arima = tabla_pronostico_ARIMA_original
pronostico_pp = forecast
pronostico_elm = data_futuro_desnormalizado
pronostico_jrd = data_futuro_jordan



if (is.matrix(pronostico_hw)) {
  pronostico_hw <- as.data.frame(pronostico_hw)
}

fechas_hw <- seq(from = as.Date("2024-11-01"), by = "month", length.out = nrow(pronostico_hw))

pronostico_hw <- data.frame(
  Fecha = fechas_hw,          # Columna de fechas
  Pronostico_hw = pronostico_hw[, "fit"]  # Valores ajustados desde la columna "fit"
)


  
# Verificar si pronostico_pp es un dataframe
if (is.data.frame(pronostico_pp)) {
  # Extraer las fechas
  fechas_pp <- pronostico_pp$ds
  
  # Crear el data.frame con las columnas necesarias
  pronostico_pp <- data.frame(
    Fecha = fechas_pp,               # Columna de fechas
    Pronostico_pp = pronostico_pp$trend # Columna de pron칩stico, que es el valor de la tendencia
  )
  
}

# print(pronostico_hw)
# print(pronostico_arima)
# print(pronostico_pp)
# print(pronostico_elm)
# print(pronostico_jrd)


pronostico_pp$Fecha <- as.Date(pronostico_pp$Fecha)
pronostico_hw$Fecha <- as.Date(pronostico_hw$Fecha)
pronostico_arima$Fecha <- as.Date(pronostico_arima$Fecha)
pronostico_elm$Fecha <- as.Date(pronostico_elm$Fecha)
pronostico_jrd$Fecha <- as.Date(pronostico_jrd$Fecha)

# Crear la tabla comparativa uniendo todas las predicciones
tabla_comparativa <- pronostico_hw %>%
  rename(Pronostico_hw = Pronostico_hw) %>%  # Ya est치 correcto, no es necesario cambiar
  full_join(pronostico_arima %>% rename(Pronostico_arima = Pronostico), by = "Fecha") %>%
  full_join(pronostico_pp %>% rename(Pronostico_pp = Pronostico_pp), by = "Fecha") %>%
  full_join(pronostico_elm %>% rename(Predicciones_Elman = Predicciones_Elman), by = "Fecha") %>%
  full_join(pronostico_jrd %>% rename(Predicciones_Jordan = Predicciones_Jordan), by = "Fecha")

# Crear la columna 'Valor real' con los valores para los periodos de noviembre y diciembre de 2024
valor_real <- rep(NA, nrow(tabla_comparativa))  # Inicializar la columna con NA

# Asignar el valor 9.75 a las filas correspondientes a noviembre y diciembre de 2024
valor_real[tabla_comparativa$Fecha == "2024-11-01"] <- 9.75
valor_real[tabla_comparativa$Fecha == "2024-12-01"] <- 9.75

# A침adir la columna 'Valor real' al inicio de la tabla comparativa
tabla_comparativa <- tabla_comparativa %>%
  mutate(Valor_real = valor_real) %>%
  select(Fecha, Valor_real, everything())  # Reorganizar para poner 'Valor_real' al inicio



print(tabla_comparativa)



```


```{r echo=FALSE, warning=FALSE}

library(knitr)

# Mostrar la tabla con kable
kable(tabla_comparativa, format = "markdown", caption = "Tabla Comparativa de Pron칩sticos")


```


La variabilidad entre los modelos es notable. Mientras que Holt-Winters, ARIMA y Prophet sugieren un crecimiento, Elman y Jordan sugieren una disminuci칩n, lo que podr칤a reflejar diferencias en los m칠todos y tipos de datos que cada uno de estos modelos utiliza. Esto sugiere que hay divergencias significativas en la naturaleza de los datos que estos modelos est치n capturando.

En cuanto al ajuste, dado que se espera que la tasa se estabilice o disminuya (y esto se puede evidenciar en el comportamiento de noviembre y diciembre), los modelos Elman y Jordan podr칤an estar capturando la tendencia de manera m치s precisa.

Se evidencia tambi칠n que Prophet es el modelo m치s preciso en cuanto a la cercan칤a de sus predicciones respecto a los valores reales, esto sugiere que tiene un buen ajuste con los patrones de los datos actuales. Esto no significa necesariamente que siempre ser치 el m치s preciso, pero en este caso parece estar capturando mejor las din치micas subyacentes. Sin embargo, para asegurarse de su validez futura, es recomendable continuar evaluando su desempe침o y ajustarlo si es necesario.


En definitiva, el an치lisis realizado sobre la tasa de intervenci칩n del Banco de la Rep칰blica de Colombia ha demostrado que los diferentes modelos aplicados (ARIMA, Holt-Winters, Prophet y Redes Neuronales) tienen capacidades complementarias para capturar las din치micas de esta serie temporal, cada uno con fortalezas espec칤ficas.

De manera general, las Redes Neuronales, en especial la Red Elman, destacan por su habilidad para modelar relaciones complejas y no lineales en la serie. No obstante, modelos como Prophet son opciones igualmente v치lidas debido a su flexibilidad para incorporar eventos at칤picos y su facilidad de configuraci칩n. 

Tanto para los modelos estad칤sticos como para las redes neuronales, es crucial realizar una b칰squeda sistem치tica de hiperpar치metros para garantizar un ajuste 칩ptimo, por ejemplo, en las Redes Neuronales, ajustar el n칰mero de neuronas en la capa oculta, variar la tasa de aprendizaje y los coeficientes de regularizaci칩n. En el caso de Prophet, optimizar la configuraci칩n de estacionalidad y ajustar la sensibilidad a eventos at칤picos o discontinuidades en la serie.

Tambi칠n podr칤a considerarse mejorar la capacidad predictiva mediante la incorporaci칩n de factores econ칩micos adicionales como:

* Inflaci칩n (IPC).
* Tasas de cambio (peso frente al d칩lar).
* Precios del petr칩leo, dado su impacto en la econom칤a colombiana.
* Indicadores internacionales como tasas de inter칠s de la Reserva Federal (FED).


Tambi칠n es pertinente realizar validaciones cruzadas para garantizar que los modelos no est칠n sobreajustados a datos hist칩ricos espec칤ficos.

Finalmente, cualquiera sea la mejora que se pruebe, sin duda concluimos que en esta serie que tiene una alta volatilidad y susceptibilidad a variables del entorno, es importante simplificar la Serie Temporal, limitando el horizonte de datos a un periodo m치s reciente (por ejemplo, 칰ltimos 5 a침os) para enfocar el an치lisis en las condiciones econ칩micas actuales y reducir la sensibilidad a ruidos hist칩ricos o din치micas econ칩micas que ya no son relevantes.



